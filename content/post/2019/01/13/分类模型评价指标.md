---
title: "分类模型评价指标"
date: 2019-01-13T22:00:23+08:00
draft: false
tags: ["科研", "分类模型", "评价指标"]
categories: ["科研","评价指标"]
toc: false
---

> 分类方法常用的评估模型好坏的方法，一般的用于机器学习，但是其他领域也可以用来评价。

# 几个概念

TP（True Precision）：表示正确预测的数目，就是完全符合算法的样本的数目。

FP（False Precision）：表示预测错误的数目，就是在自己预测的样本中，有些样本被预测出来了但是它是不符合算法的，一般的是程序或者编写程序错误、算法不够完善导致的。

TN（True Not Precision）：表示正确预测出错误样本数目，在所有的检测样本中，有些样本是不符合算法的，并且没有被检测出来的样本的数目。

FN（False Not Precision）：表示错误预测符合算法的样本为错误样本的数目。

你看到这或许有点云里雾里，看下下面的案例或许就会清楚很多。

# 案例

有一批水果，其中橘子假如是7个，苹果有10个。现在有一套程序，挑选出所有的橘子，程序检测出来了6个橘子，而实际情况是6个橘子中有一个苹果，即把5个橘子1个苹果当成了6个苹果。

TP是正确预测出来的数目，就是5(`程序检测出来的6个橘子中有5个就是橘子`)，那么其中FP就是1(`1个苹果被认为是橘子`)，TN是被正确预测出来不是样本的数目就是9（`10个苹果中有一个苹果被认为是橘子了`），FN就是1(`中一个橘子被认为是苹果，也就是没有被检测出来`).

# 评价

1. 其中最常用的是Precision，就是精度。

![https://oss.lucoder.com/uploads/2019/01/13/20190113220415.png](https://oss.lucoder.com/uploads/2019/01/13/20190113220415.png)

2. 其中关注真实样本的数据中正确预测的比例使用`Recall`来衡量。

![https://oss.lucoder.com/uploads/2019/01/13/20190113220513.png](https://oss.lucoder.com/uploads/2019/01/13/20190113220513.png)

3. 然后就是最终的衡量公式`F-Score`。

![https://oss.lucoder.com/uploads/2019/01/13/20190113220822.png](https://oss.lucoder.com/uploads/2019/01/13/20190113220822.png)

需要解释一下，对于1、2公式无可厚非，TP、TF、FP、FN都已经介绍，主要着重介绍一下F-Score中的变量β，其中β是一个权重用于指定精度和召回率那个更重要。其实认真观察公式就可看出，当β值大于1时候，显然`Recall`更加重要，如果是小于1则表示`Precision`更加重要，但是一般的都会选择β是1表示两个一样重要，变形成为下面的公式。

# 计算

通过分析阶段已经的到下面的这几组值：

```
TP = 5
FP = 1
TN = 9
FN = 1
```

所以的到最后的结果是：

```
Precision   = 1/6
Recall      = 1/6
F-Score     = 1/27
```

本文的案例纯属巧合，得到了一组Precision和Recall相等的一组数据，一般的这两个有一种反比的结果趋势（`注意：其实没太大关系，但是往往有这么一种趋势`），即当`Recall`比较大时候`Precision`比较小，反之亦然。